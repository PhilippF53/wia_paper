@article{severityscores,
  title = {Proposed International Clinical Diabetic Retinopathy and Diabetic Macular Edema Disease Severity Scales},
  author = {Wilkinson, C.P and Ferris, Frederick L and Klein, Ronald E and Lee, Paul P and Agardh, Carl David and Davis, Matthew and Dills, Diana and Kampik, Anselm and Pararajasegaram, R and Verdaguer, Juan T},
  date = {2003-09},
  journaltitle = {Ophthalmology},
  shortjournal = {Ophthalmology},
  volume = {110},
  number = {9},
  pages = {1677--1682},
  issn = {01616420},
  doi = {10.1016/S0161-6420(03)00475-5},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0161642003004755},
  urldate = {2025-05-19},
  abstract = {Purpose: To develop consensus regarding clinical disease severity classification systems for diabetic retinopathy and diabetic macular edema that can be used around the world, and to improve communication and coordination of care among physicians who care for patients with diabetes. Design: Report regarding the development of clinical diabetic retinopathy disease severity scales. Participants: A group of 31 individuals from 16 countries, representing comprehensive ophthalmology, retina subspecialties, endocrinology, and epidemiology. Methods: An initial clinical classification system, based on the Early Treatment Diabetic Retinopathy Study and the Wisconsin Epidemiologic Study of Diabetic Retinopathy publications, was circulated to the group in advance of a workshop. Each member reviewed this using e-mail, and a modified Delphi system was used to stratify responses. At a later workshop, separate systems for diabetic retinopathy and macular edema were developed. These were then reevaluated by group members, and the modified Delphi system was again used to measure degrees of agreement. Main Outcome Measures: Consensus regarding specific classification systems was achieved. Results: A five-stage disease severity classification for diabetic retinopathy includes three stages of low risk, a fourth stage of severe nonproliferative retinopathy, and a fifth stage of proliferative retinopathy. Diabetic macular edema is classified as apparently present or apparently absent. If training and equipment allow the screener to make a valid decision, macular edema is further categorized as a function of its distance from the central macula. Conclusions: There seems to be a genuine need for consistent international clinical classification systems for diabetic retinopathy and diabetic macular edema that are supported with solid evidence. The proposed clinical classification systems provide a means of appropriately categorizing diabetic retinopathy and macular edema. It is hoped that these systems will be valuable in improving both screening of individuals with diabetes and communication and discussion among individuals caring for these patients. Ophthalmology 2003;110: 1677–1682 © 2003 by the American Academy of Ophthalmology.},
  langid = {english},
  file = {C:\Users\phili\Zotero\storage\FCUWWVH7\Wilkinson et al. - 2003 - Proposed international clinical diabetic retinopathy and diabetic macular edema disease severity sca.pdf}
}
@incollection{experteninterviews,
  title = {Leitfaden- und Experteninterviews},
  booktitle = {Handbuch Methoden der empirischen Sozialforschung},
  author = {Helfferich, Cornelia},
  editor = {Baur, Nina and Blasius, Jörg},
  date = {2022},
  pages = {875--892},
  publisher = {Springer Fachmedien},
  location = {Wiesbaden},
  doi = {10.1007/978-3-658-37985-8_55},
  url = {https://doi.org/10.1007/978-3-658-37985-8_55},
  urldate = {2025-05-19},
  abstract = {Qualitative, leitfadengestützte Interviews sind eine verbreitete, ausdifferenzierte und methodologisch vergleichsweise gut ausgearbeitete Methode, qualitative Daten zu erzeugen. Leitfadeninterviews gestalten die Führung im Interview über einen vorbereiteten Leitfaden, Experteninterviews sind definiert über die spezielle Auswahl und den Status der Befragten.},
  isbn = {978-3-658-37985-8},
  langid = {ngerman},
  file = {C:\Users\phili\Zotero\storage\TZFFAZQV\Helfferich - 2022 - Leitfaden- und Experteninterviews.pdf}
}
@article{messidor21,
  title = {Automated {{Analysis}} of {{Retinal Images}} for {{Detection}} of {{Referable Diabetic Retinopathy}}},
  author = {Abr{\`a}moff, Michael D. and Folk, James C. and Han, Dennis P. and Walker, Jonathan D. and Williams, David F. and Russell, Stephen R. and Massin, Pascale and Cochener, Beatrice and Gain, Philippe and Tang, Li and Lamard, Mathieu and Moga, Daniela C. and Quellec, Gw{\'e}nol{\'e} and Niemeijer, Meindert},
  year = {2013},
  month = mar,
  journal = {JAMA Ophthalmology},
  volume = {131},
  number = {3},
  pages = {351--357},
  issn = {2168-6165},
  doi = {10.1001/jamaophthalmol.2013.1743},
  urldate = {2025-05-22},
  abstract = {The diagnostic accuracy of computer detection programs has been reported to be comparable to that of specialists and expert readers, but no computer detection programs have been validated in an independent cohort using an internationally recognized diabetic retinopathy (DR) standard.To determine the sensitivity and specificity of the Iowa Detection Program (IDP) to detect referable diabetic retinopathy (RDR).In primary care DR clinics in France, from January 1, 2005, through December 31, 2010, patients were photographed consecutively, and retinal color images were graded for retinopathy severity according to the International Clinical Diabetic Retinopathy scale and macular edema by 3 masked independent retinal specialists and regraded with adjudication until consensus. The IDP analyzed the same images at a predetermined and fixed set point. We defined RDR as more than mild nonproliferative retinopathy and/or macular edema.A total of 874 people with diabetes at risk for DR.Sensitivity and specificity of the IDP to detect RDR, area under the receiver operating characteristic curve, sensitivity and specificity of the retinal specialists' readings, and mean interobserver difference ({$\kappa$}).The RDR prevalence was 21.7\% (95\% CI, 19.0\%-24.5\%). The IDP sensitivity was 96.8\% (95\% CI, 94.4\%-99.3\%) and specificity was 59.4\% (95\% CI, 55.7\%-63.0\%), corresponding to 6 of 874 false-negative results (none met treatment criteria). The area under the receiver operating characteristic curve was 0.937 (95\% CI, 0.916-0.959). Before adjudication and consensus, the sensitivity/specificity of the retinal specialists were 0.80/0.98, 0.71/1.00, and 0.91/0.95, and the mean intergrader {$\kappa$} was 0.822.The IDP has high sensitivity and specificity to detect RDR. Computer analysis of retinal photographs for DR and automated detection of RDR can be implemented safely into the DR screening pipeline, potentially improving access to screening and health care productivity and reducing visual loss through early treatment.},
  file = {C:\Users\phili\Zotero\storage\9TYYM3QE\1668203.html}
}
@article{messidor22,
  title = {{{FEEDBACK ON A PUBLICLY DISTRIBUTED IMAGE DATABASE}}: {{THE MESSIDOR DATABASE}}},
  shorttitle = {{{FEEDBACK ON A PUBLICLY DISTRIBUTED IMAGE DATABASE}}},
  author = {Decenci{\`e}re, Etienne and Zhang, Xiwei and Cazuguel, Guy and Lay, Bruno and Cochener, B{\'e}atrice and Trone, Caroline and Gain, Philippe and Ordonez, Richard and Massin, Pascale and Erginay, Ali and Charton, B{\'e}atrice and Klein, Jean-Claude},
  year = {2014},
  month = aug,
  journal = {Image Analysis and Stereology},
  volume = {33},
  number = {3},
  pages = {231--234},
  issn = {1854-5165},
  doi = {10.5566/ias.1155},
  urldate = {2025-05-22},
  abstract = {The Messidor database, which contains hundreds of eye fundus images, has been publicly distributed since 2008. It was created by the Messidor project in order to evaluate automatic lesion segmentation and diabetic retinopathy grading methods. Designing, producing and maintaining such a database entails significant costs. By publicly sharing it, one hopes to bring a valuable resource to the public research community. However, the real interest and benefit of the research community is not easy to quantify. We analyse here the feedback on the Messidor database, after more than 6 years of diffusion. This analysis should apply to other similar research databases.},
  copyright = {Copyright (c) 2014 Image Analysis \& Stereology},
  langid = {english},
  keywords = {diabetic retinopathy,image database,image processing,Messidor},
  file = {C:\Users\phili\Zotero\storage\UJNCIYJU\Decencière et al. - 2014 - FEEDBACK ON A PUBLICLY DISTRIBUTED IMAGE DATABASE THE MESSIDOR DATABASE.pdf}
}
@article{teleophta,
  title = {{{TeleOphta}}: {{Machine}} Learning and Image Processing Methods for Teleophthalmology},
  shorttitle = {{{TeleOphta}}},
  author = {Decenci{\`e}re, E. and Cazuguel, G. and Zhang, X. and Thibault, G. and Klein, J.-C. and Meyer, F. and Marcotegui, B. and Quellec, G. and Lamard, M. and Danno, R. and Elie, D. and Massin, P. and Viktor, Z. and Erginay, A. and La{\"y}, B. and Chabouis, A.},
  year = {2013},
  month = apr,
  journal = {IRBM},
  volume = {34},
  number = {2},
  pages = {196--203},
  issn = {19590318},
  doi = {10.1016/j.irbm.2013.01.010},
  urldate = {2025-05-22},
  abstract = {A complete prototype for the automatic detection of normal examinations on a teleophthalmology network for diabetic retinopathy screening is presented. The system combines pathological pattern mining methods, with specific lesion detection methods, to extract information from the images. This information, plus patient and other contextual data, is used by a classifier to compute an abnormality risk. Such a system should reduce the burden on readers on teleophthalmology networks.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {C:\Users\phili\Zotero\storage\2URG6Z5M\Decencière et al. - 2013 - TeleOphta Machine learning and image processing methods for teleophthalmology.pdf}
}
@article{usability,
  title = {Quality of Human-Computer Interaction - Results of a National Usability Survey of Hospital-{{IT}} in {{Germany}}},
  author = {Bundschuh, Bettina B and Majeed, Raphael W and B{\"u}rkle, Thomas and Kuhn, Klaus and Sax, Ulrich and Seggewies, Christof and Vosseler, Cornelia and R{\"o}hrig, Rainer},
  year = {2011},
  month = dec,
  journal = {BMC Medical Informatics and Decision Making},
  volume = {11},
  number = {1},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {1472-6947},
  doi = {10.1186/1472-6947-11-69},
  urldate = {2025-05-22},
  abstract = {Abstract                      Background            Due to the increasing functionality of medical information systems, it is hard to imagine day to day work in hospitals without IT support. Therefore, the design of dialogues between humans and information systems is one of the most important issues to be addressed in health care. This survey presents an analysis of the current quality level of human-computer interaction of healthcare-IT in German hospitals, focused on the users' point of view.                                Methods            To evaluate the usability of clinical-IT according to the design principles of EN ISO 9241-10 the IsoMetrics Inventory, an assessment tool, was used. The focus of this paper has been put on suitability for task, training effort and conformity with user expectations, differentiated by information systems. Effectiveness has been evaluated with the focus on interoperability and functionality of different IT systems.                                Results            4521 persons from 371 hospitals visited the start page of the study, while 1003 persons from 158 hospitals completed the questionnaire. The results show relevant variations between different information systems.                                Conclusions            Specialised information systems with defined functionality received better assessments than clinical information systems in general. This could be attributed to the improved customisation of these specialised systems for specific working environments. The results can be used as reference data for evaluation and benchmarking of human computer engineering in clinical health IT context for future studies.},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {C:\Users\phili\Zotero\storage\C8Z8A8FK\Bundschuh et al. - 2011 - Quality of human-computer interaction - results of a national usability survey of hospital-IT in Ger.pdf}
}
@incollection{akzeptanz,
  title = {{Digitalisierung im Krankenhaus: Nutzerakzeptanz als Voraussetzung f{\"u}r digitale Innovationen}},
  shorttitle = {{Digitalisierung im Krankenhaus}},
  booktitle = {{Innovationen und Innovationsmanagement im Gesundheitswesen : Technologien, Produkte und Dienstleistungen voranbringen}},
  author = {{Schmidt-Logenthiran}, Tobias and Stephan, Michael},
  editor = {Pfannstiel, Mario A. and Kassel, Kristin and Rasche, Christoph},
  year = {2020},
  pages = {667--681},
  publisher = {Springer Fachmedien},
  address = {Wiesbaden},
  doi = {10.1007/978-3-658-28643-9_35},
  urldate = {2025-05-22},
  abstract = {Die Investitionen der Krankenh{\"a}user in digitale Innovationen haben in den letzten Jahren stark zugenommen und werden aufgrund unterschiedlicher gesellschaftlicher Entwicklungen voraussichtlich auch in den kommenden Jahren weiter ansteigen. Um die knappen Ressourcen der Krankenh{\"a}user m{\"o}glichst optimal einzusetzen, ist es notwendig sicherzustellen, dass die innovativen Systeme auch von den Mitarbeitern der Krankenh{\"a}user genutzt werden. Voraussetzung f{\"u}r die Nutzung ist dabei die Akzeptanz aufseiten der Mitarbeiter, die bei oft disruptiven Innovationen nicht gleich gegeben ist. Als ,,Kerntechnologie`` kommt dem Krankenhausinformationssystem dabei eine tragende Rolle zu, da es Aufsatzpunkt f{\"u}r die meisten digitalen Erneuerungen im Krankenhaus ist. Das Management kann bei der Implementierung solcher Innovationen durch bestimmte Aktivit{\"a}ten die Nutzerakzeptanz erh{\"o}hen und so zum erfolgreichen digitalen Wandel im Krankenhaus beitragen.},
  isbn = {978-3-658-28643-9},
  langid = {ngerman},
  file = {C:\Users\phili\Zotero\storage\SBNP44FS\Schmidt-Logenthiran und Stephan - 2020 - Digitalisierung im Krankenhaus Nutzerakzeptanz als Voraussetzung für digitale Innovationen.pdf}
}
@misc{IncreasingIncidenceDiabetes,
  title = {The {{Increasing Incidence}} of {{Diabetes}} in the 21st {{Century}}},
  doi = {10.1177/193229680900300101},
  urldate = {2025-05-08},
  howpublished = {https://journals.sagepub.com/doi/epdf/10.1177/193229680900300101},
  langid = {english},
  file = {C\:\\Users\\phili\\Zotero\\storage\\YW5ZMAQ6\\The Increasing Incidence of Diabetes in the 21st Century.pdf;C\:\\Users\\phili\\Zotero\\storage\\PU5U4GHH\\193229680900300101.html}
}
@article{lecunDeepLearning2015a,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature14539},
  urldate = {2025-06-02},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  copyright = {2015 Springer Nature Limited},
  langid = {english},
  keywords = {Computer science,Mathematics and computing},
  file = {C:\Users\phili\Zotero\storage\UBQQW2NL\LeCun et al. - 2015 - Deep learning.pdf}
}
@article{SurveyConvolutionalNeural2022,
  title = {A {{Survey}} of {{Convolutional Neural Networks}}: {{Analysis}}, {{Applications}}, and {{Prospects}}},
  shorttitle = {A {{Survey}} of {{Convolutional Neural Networks}}},
  author = {Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  year = {2022},
  month = dec,
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {33},
  number = {12},
  pages = {6999--7019},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2021.3084827},
  urldate = {2025-06-10},
  abstract = {A convolutional neural network (CNN) is one of the most significant networks in the deep learning field. Since CNN made impressive achievements in many areas, including but not limited to computer vision and natural language processing, it attracted much attention from both industry and academia in the past few years. The existing reviews mainly focus on CNN's applications in different scenarios without considering CNN from a general perspective, and some novel ideas proposed recently are not covered. In this review, we aim to provide some novel ideas and prospects in this fast-growing field. Besides, not only 2-D convolution but also 1-D and multidimensional ones are involved. First, this review introduces the history of CNN. Second, we provide an overview of various convolutions. Third, some classic and advanced CNN models are introduced; especially those key points making them reach state-of-the-art results. Fourth, through experimental analysis, we draw some conclusions and provide several rules of thumb for functions and hyperparameter selection. Fifth, the applications of 1-D, 2-D, and multidimensional convolution are covered. Finally, some open issues and promising directions for CNN are discussed as guidelines for future work.},
  keywords = {Computer vision,Convolutional neural networks,convolutional neural networks (CNNs),deep learning,Deep learning,deep neural networks,Feature extraction,Neurons},
  file = {C\:\\Users\\phili\\Zotero\\storage\\IV6WUASH\\Li et al. - 2022 - A Survey of Convolutional Neural Networks Analysis, Applications, and Prospects.pdf;C\:\\Users\\phili\\Zotero\\storage\\2LZ29MXV\\9451544.html}
}
@misc{IntroductionConvolutionalNeural2015,
  title = {An {{Introduction}} to {{Convolutional Neural Networks}}},
  author = {O'Shea, Keiron and Nash, Ryan},
  year = {2015},
  month = dec,
  number = {arXiv:1511.08458},
  eprint = {1511.08458},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1511.08458},
  urldate = {2025-06-10},
  abstract = {The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C\:\\Users\\phili\\Zotero\\storage\\HXGWMHEJ\\O'Shea und Nash - 2015 - An Introduction to Convolutional Neural Networks.pdf;C\:\\Users\\phili\\Zotero\\storage\\J8VELVHP\\1511.html}
}
@article{gulshanDevelopmentValidationDeep2016a,
  title = {Development and {{Validation}} of a {{Deep Learning Algorithm}} for {{Detection}} of {{Diabetic Retinopathy}} in {{Retinal Fundus Photographs}}},
  author = {Gulshan, Varun and Peng, Lily and Coram, Marc and Stumpe, Martin C. and Wu, Derek and Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Widner, Kasumi and Madams, Tom and Cuadros, Jorge and Kim, Ramasamy and Raman, Rajiv and Nelson, Philip C. and Mega, Jessica L. and Webster, Dale R.},
  year = {2016},
  month = dec,
  journal = {JAMA},
  volume = {316},
  number = {22},
  pages = {2402},
  issn = {0098-7484},
  doi = {10.1001/jama.2016.17216},
  urldate = {2025-06-10},
  abstract = {OBJECTIVE To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs. DESIGN AND SETTING A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency. EXPOSURE Deep learning--trained algorithm. MAIN OUTCOMES AND MEASURES The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity. RESULTS The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2\% women; prevalence of RDR, 683/8878 fully gradable images [7.8\%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6\% women; prevalence of RDR, 254/1745 fully gradable images [14.6\%]). For detecting RDR, the algorithm had an area under the receiver operating curve of 0.991 (95\% CI, 0.988-0.993) for EyePACS-1 and 0.990 (95\% CI, 0.986-0.995) for Messidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivity was 90.3\% (95\% CI, 87.5\%-92.7\%) and the specificity was 98.1\% (95\% CI, 97.8\%-98.5\%). For Messidor-2, the sensitivity was 87.0\% (95\% CI, 81.1\%91.0\%) and the specificity was 98.5\% (95\% CI, 97.7\%-99.1\%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivity was 97.5\% and specificity was 93.4\% and for Messidor-2 the sensitivity was 96.1\% and specificity was 93.9\%. CONCLUSIONS AND RELEVANCE In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.},
  langid = {english},
  file = {C:\Users\phili\Zotero\storage\FLWNADPT\Gulshan et al. - 2016 - Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Ret.pdf}
}
@misc{szegedyRethinkingInceptionArchitecture2015,
  title = {Rethinking the {{Inception Architecture}} for {{Computer Vision}}},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  year = {2015},
  month = dec,
  number = {arXiv:1512.00567},
  eprint = {1512.00567},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1512.00567},
  urldate = {2025-06-10},
  abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error on the validation set (3.6\% error on the test set) and 17.3\% top-1 error on the validation set.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\phili\\Zotero\\storage\\5RGYIELP\\Szegedy et al. - 2015 - Rethinking the Inception Architecture for Computer Vision.pdf;C\:\\Users\\phili\\Zotero\\storage\\RWLBFYUM\\1512.html}
}
@article{abramoffPivotalTrialAutonomous2018,
  title = {Pivotal Trial of an Autonomous {{AI-based}} Diagnostic System for Detection of Diabetic Retinopathy in Primary Care Offices},
  author = {Abr{\`a}moff, Michael D. and Lavin, Philip T. and Birch, Michele and Shah, Nilay and Folk, James C.},
  year = {2018},
  month = aug,
  journal = {npj Digital Medicine},
  volume = {1},
  number = {1},
  pages = {39},
  issn = {2398-6352},
  doi = {10.1038/s41746-018-0040-6},
  urldate = {2025-05-06},
  abstract = {Abstract             Artificial Intelligence (AI) has long promised to increase healthcare affordability, quality and accessibility but FDA, until recently, had never authorized an autonomous AI diagnostic system. This pivotal trial of an AI system to detect diabetic retinopathy (DR) in people with diabetes enrolled 900 subjects, with no history of DR at primary care clinics, by comparing to Wisconsin Fundus Photograph Reading Center (FPRC) widefield stereoscopic photography and macular Optical Coherence Tomography (OCT), by FPRC certified photographers, and FPRC grading of Early Treatment Diabetic Retinopathy Study Severity Scale (ETDRS) and Diabetic Macular Edema (DME). More than mild DR (mtmDR) was defined as ETDRS level 35 or higher, and/or DME, in at least one eye. AI system operators underwent a standardized training protocol before study start. Median age was 59 years (range, 22--84 years); among participants, 47.5\% of participants were male; 16.1\% were Hispanic, 83.3\% not Hispanic; 28.6\% African American and 63.4\% were not; 198 (23.8\%) had mtmDR. The AI system exceeded all pre-specified superiority endpoints at sensitivity of 87.2\% (95\% CI, 81.8--91.2\%) ({$>$}85\%), specificity of 90.7\% (95\% CI, 88.3--92.7\%) ({$>$}82.5\%), and imageability rate of 96.1\% (95\% CI, 94.6--97.3\%), demonstrating AI's ability to bring specialty-level diagnostics to primary care settings. Based on these results, FDA authorized the system for use by health care providers to detect more than mild DR and diabetic macular edema, making it, the first FDA authorized autonomous AI diagnostic system in any field of medicine, with the potential to help prevent vision loss in thousands of people with diabetes annually. ClinicalTrials.gov NCT02963441},
  langid = {english},
  file = {C:\Users\phili\Zotero\storage\M4N67Y4F\Abràmoff et al. - 2018 - Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in p.pdf}
}
@article{niemeijerAutomaticDetectionRed2005,
  title = {Automatic Detection of Red Lesions in Digital Color Fundus Photographs},
  author = {Niemeijer, M. and {van Ginneken}, B. and Staal, J. and {Suttorp-Schulten}, M.S.A. and Abramoff, M.D.},
  year = {2005},
  month = may,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {24},
  number = {5},
  pages = {584--592},
  issn = {1558-254X},
  doi = {10.1109/TMI.2005.843738},
  urldate = {2025-06-11},
  abstract = {The robust detection of red lesions in digital color fundus photographs is a critical step in the development of automated screening systems for diabetic retinopathy. In this paper, a novel red lesion detection method is presented based on a hybrid approach, combining prior works by Spencer et al. (1996) and Frame et al. (1998) with two important new contributions. The first contribution is a new red lesion candidate detection system based on pixel classification. Using this technique, vasculature and red lesions are separated from the background of the image. After removal of the connected vasculature the remaining objects are considered possible red lesions. Second, an extensive number of new features are added to those proposed by Spencer-Frame. The detected candidate objects are classified using all features and a k-nearest neighbor classifier. An extensive evaluation was performed on a test set composed of images representative of those normally found in a screening set. When determining whether an image contains red lesions the system achieves a sensitivity of 100\% at a specificity of 87\%. The method is compared with several different automatic systems and is shown to outperform them all. Performance is close to that of a human expert examining the images for the presence of red lesions.},
  keywords = {Biomedical imaging,Blindness,Cities and towns,Computer-aided diagnosis,Diabetes,fundus,Lesions,Medical diagnostic imaging,microaneurysms,Object detection,Performance evaluation,pixel classification,red lesions,retina,Retinopathy,Robustness,screening},
  file = {C:\Users\phili\Zotero\storage\LNBNIMS8\Niemeijer et al. - 2005 - Automatic detection of red lesions in digital color fundus photographs.pdf}
}
